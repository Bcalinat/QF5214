{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import requests\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/bcalinat/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "Comps = [\"MSFT\", \"AAPL\", \"NVDA\", \"AVGO\", \"BRK-B\", \"JPM\",\n",
    "         \"LLY\", \"UNH\", \"AMZN\", \"GE\", \"GOOG\", \"WMT\", \"XOM\", \"LIN\",]\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsapi return example:\n",
    "# {'status': 'ok',\n",
    "#  'totalResults': 123,\n",
    "#  'articles': [{'source': {'id': None, 'name': 'Biztoc.com'},\n",
    "#    'author': 'investors.com',\n",
    "#    'title': \"xxxxxx\",\n",
    "#    'description': 'xxxxx',\n",
    "#    'url': 'https://xxxxx',\n",
    "#    'urlToImage': 'https://xxxxxxx',\n",
    "#    'publishedAt': '2024-03-01T23:28:14Z',\n",
    "#    'content': \"xxxxx\"},\n",
    "#  ]\n",
    "# }\n",
    "\n",
    "# use example -> get_news(\"MSFT\", \"2024-03-01\", \"2022-04-01\")\n",
    "def get_news_by_newsapi(query: str, fromTime: str, toTime: str):\n",
    "    api_key = '490c4bd988b94431886ee1bd945a5e11'\n",
    "    url = 'https://newsapi.org/v2/everything'\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'from': fromTime,\n",
    "        'to': toTime,\n",
    "        'sortBy': 'publishedAt',\n",
    "        'apiKey': api_key\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    # print(data)\n",
    "    resp = []\n",
    "    for i in data['articles']:\n",
    "        resp.append({\n",
    "\t\t\t'content': i['content'],\n",
    "            'url': i['url'],\n",
    "\t\t\t'publishedAt': i['publishedAt'],\n",
    "            'title': i['title']\n",
    "        })\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_score return example: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
    "# compound 是最终打分，大于0为正面，小于0为负面\n",
    "def get_score(text: str):\n",
    "    score = sia.polarity_scores(text)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_month_news_for_company: 对股票(公司)名，获取从202X到202X年每个月的新闻打分细节\n",
    "def get_month_news_for_company(compName: str, startYear: int, endYear: int):\n",
    "\tnews = []\n",
    "\tfor y in range(startYear, endYear + 1): # 遍历从202X到202X年\n",
    "\t\tfor m in range(1, 12): # 遍历12个月\n",
    "            #\n",
    "            # \n",
    "\t\t\tcomp_news = get_news_by_newsapi(compName, f'{y}-{m}-1', f'{y}-{m+1}-1')\n",
    "\t\t\tfor artical in comp_news['articles']:\n",
    "\t\t\t\tscore = get_score(artical['content']) \n",
    "\t\t\t\tnews.append({\n",
    "\t\t\t\t\t'name': compName,\n",
    "\t\t\t\t\t'url': artical['url'],\n",
    "\t\t\t\t\t'publishedAt': artical['publishedAt'],\n",
    "\t\t\t\t\t'compound': score['compound'],\n",
    "\t\t\t\t})\n",
    "\treturn news\n",
    "\n",
    "# 获取所有公司的记录\n",
    "def get_month_news_for_companies(comps: list, startYear: int, endYear: int):\n",
    "    return [get_month_news_for_company(comp, startYear, endYear) for comp in comps]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
